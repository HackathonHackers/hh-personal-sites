#!/usr/bin/env python

from __future__ import print_function

import os
import sys
import requests


def extract_names(file_name):
    with open(file_name, 'r') as f:
        for line in f:
            # Probably should look for -\S+[A-Za-z\S]+ <url> instead
            if line.startswith('- '):
                yield line.split(' ', 1)[1]


def strip_url(s):
    return " ".join(s.strip().split(' ')[:-1])


def return_url(s):
    return s.strip().split(' ')[-1]


def check_line_for_reachable_url(line, file):
    if line.startswith('- '):
        url = return_url(line)
        get = requests.get(url)
        # if the request succeeds
        if get.status_code == 200:
            file.write(line)
    else:
        file.write(line)
             

def drop_dead_urls():
    for file_name in ['README.md', 'github.md']:
        with open(file_name, "r") as f:
            lines = f.readlines()
        with open(file_name, "w") as f:
            for line in lines:
                check_line_for_reachable_url(line, f)
                

def validate_ordering():
    ret_val = 0
    for file_name in ['README.md', 'github.md']:
        if not os.path.exists(file_name):
            print(' [-] Aborting commit: expecting %s to exist'%file_name)
            ret_val = 1
        else:
            print(' [+] Checking %s'%file_name)
            prev_line = None
            for line in extract_names(file_name):
                if prev_line is not None and line.lower() < prev_line.lower():
                    print(" [-] Aborting commit: %s and %s are out of order!"%(
                        strip_url(line),
                        strip_url(prev_line)))
                    ret_val = 1
                prev_line = line
    drop_dead_urls()
    return ret_val


if __name__ == '__main__':
    sys.exit(validate_ordering())
